{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrogram Channels U-net\n",
    "\n",
    "* SPECTROGRAM-CHANNELS U-NET: A SOURCE SEPARATION MODEL VIEWING EACH CHANNEL AS THE SPECTROGRAM OF EACH SOURCE, [arXiv:1810.11520](https://arxiv.org/abs/1810.11520)\n",
    "  * Jaehoon Oh∗, Duyeon Kim∗, Se-Young Yun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import PIL\n",
    "import imageio\n",
    "from IPython import display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Flags (hyperparameter configuration)\n",
    "model_name = 'spectrogram_unet'\n",
    "train_dir = 'train/' + model_name + '/exp1/'\n",
    "max_epochs = 200\n",
    "save_model_epochs = 20\n",
    "print_steps = 1\n",
    "batch_size = 8\n",
    "learning_rate = 2e-4\n",
    "N = 100 # number of samples in train_dataset\n",
    "\n",
    "BUFFER_SIZE = N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up dataset with `tf.data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/spectrogram/train/spectrogram_train_00000-of-00020.tfrecord\n",
      "./datasets/spectrogram/train/spectrogram_train_00001-of-00020.tfrecord\n",
      "./datasets/spectrogram/train/spectrogram_train_00002-of-00020.tfrecord\n",
      "./datasets/spectrogram/train/spectrogram_train_00003-of-00020.tfrecord\n",
      "./datasets/spectrogram/train/spectrogram_train_00004-of-00020.tfrecord\n",
      "./datasets/spectrogram/train/spectrogram_train_00005-of-00020.tfrecord\n",
      "./datasets/spectrogram/train/spectrogram_train_00006-of-00020.tfrecord\n",
      "./datasets/spectrogram/train/spectrogram_train_00007-of-00020.tfrecord\n",
      "./datasets/spectrogram/train/spectrogram_train_00008-of-00020.tfrecord\n",
      "./datasets/spectrogram/train/spectrogram_train_00009-of-00020.tfrecord\n",
      "./datasets/spectrogram/train/spectrogram_train_00010-of-00020.tfrecord\n",
      "./datasets/spectrogram/train/spectrogram_train_00011-of-00020.tfrecord\n",
      "./datasets/spectrogram/train/spectrogram_train_00012-of-00020.tfrecord\n",
      "./datasets/spectrogram/train/spectrogram_train_00013-of-00020.tfrecord\n",
      "./datasets/spectrogram/train/spectrogram_train_00014-of-00020.tfrecord\n",
      "./datasets/spectrogram/train/spectrogram_train_00015-of-00020.tfrecord\n",
      "./datasets/spectrogram/train/spectrogram_train_00016-of-00020.tfrecord\n",
      "./datasets/spectrogram/train/spectrogram_train_00017-of-00020.tfrecord\n",
      "./datasets/spectrogram/train/spectrogram_train_00018-of-00020.tfrecord\n",
      "./datasets/spectrogram/train/spectrogram_train_00019-of-00020.tfrecord\n"
     ]
    }
   ],
   "source": [
    "data_path = './datasets/spectrogram/'\n",
    "train_data_filenames = [os.path.join(data_path, 'train', name)\n",
    "                        for name in os.listdir(os.path.join(data_path, 'train')) if 'tfrecord' in name]\n",
    "for name in train_data_filenames:\n",
    "  print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(example_proto):\n",
    "  features = {'spec_raw': tf.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "              'frequency_bin': tf.FixedLenFeature([], tf.int64, default_value=0),\n",
    "              'time_step': tf.FixedLenFeature([], tf.int64, default_value=0),\n",
    "              'channel': tf.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "              'track_number': tf.FixedLenFeature([], tf.int64, default_value=0),\n",
    "              'split_number': tf.FixedLenFeature([], tf.int64, default_value=0),}\n",
    "  \n",
    "  parsed_features = tf.parse_single_example(example_proto, features)\n",
    "\n",
    "  spec_raw = tf.decode_raw(parsed_features[\"spec_raw\"], out_type=tf.float32)\n",
    "  frequency_bin = tf.cast(parsed_features[\"frequency_bin\"], dtype=tf.int32)\n",
    "  time_step = tf.cast(parsed_features[\"time_step\"], dtype=tf.int32)\n",
    "  #channel = tf.cast(parsed_features[\"channel\"], dtype=tf.string)\n",
    "  #track_number = tf.cast(parsed_features[\"track_number\"], dtype=tf.int32)\n",
    "  #split_number = tf.cast(parsed_features[\"split_number\"], dtype=tf.int32)\n",
    "  \n",
    "  num_channels = 6 # for [mixtures, vocals, drums, basses, others, accompaniments]\n",
    "  spec_raw = tf.reshape(spec_raw, shape=[frequency_bin, time_step, num_channels])\n",
    "\n",
    "  return spec_raw, time_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _augmentation_function(spec_raw, time_step):\n",
    "  \"\"\"Random cropping for data augmentation\n",
    "  \"\"\"\n",
    "  target_time_step = 128 # our input size\n",
    "  available_time_step = time_step - target_time_step\n",
    "  \n",
    "  crop_index = tf.random_uniform(shape=[]) * tf.cast(available_time_step, dtype=tf.float32)\n",
    "  crop_index = tf.cast(crop_index, dtype=tf.int32)\n",
    "  spec_raw_crop = spec_raw[:, crop_index:crop_index+target_time_step, :]\n",
    "  \n",
    "  return spec_raw_crop[..., 0:1], spec_raw_crop[..., 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_data_filenames)\n",
    "train_dataset = train_dataset.map(_parse_function)\n",
    "train_dataset = train_dataset.map(_augmentation_function)\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Downsample(tf.keras.Model):\n",
    "    \n",
    "  def __init__(self, filters, size, apply_batchnorm=True):\n",
    "    super(Downsample, self).__init__()\n",
    "    self.apply_batchnorm = apply_batchnorm\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    self.conv1 = tf.keras.layers.Conv2D(filters, \n",
    "                                        (size, size), \n",
    "                                        strides=2, \n",
    "                                        padding='same',\n",
    "                                        kernel_initializer=initializer,\n",
    "                                        use_bias=False)\n",
    "    if self.apply_batchnorm:\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "  \n",
    "  def call(self, x, training):\n",
    "    x = self.conv1(x)\n",
    "    if self.apply_batchnorm:\n",
    "        x = self.batchnorm(x, training=training)\n",
    "    x = tf.nn.leaky_relu(x) # a = 0.2\n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(tf.keras.Model):\n",
    "    \n",
    "  def __init__(self, filters, size, apply_dropout=False):\n",
    "    super(Upsample, self).__init__()\n",
    "    self.apply_dropout = apply_dropout\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    self.up_conv = tf.keras.layers.Conv2DTranspose(filters, \n",
    "                                                   (size, size), \n",
    "                                                   strides=2, \n",
    "                                                   padding='same',\n",
    "                                                   kernel_initializer=initializer,\n",
    "                                                   use_bias=False)\n",
    "    self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "    if self.apply_dropout:\n",
    "        self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "\n",
    "  def call(self, x1, x2, training):\n",
    "    x = self.up_conv(x1)\n",
    "    x = self.batchnorm(x, training=training)\n",
    "    if self.apply_dropout:\n",
    "        x = self.dropout(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = tf.concat([x, x2], axis=-1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramChannelsUNet(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(SpectrogramChannelsUNet, self).__init__()\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    \n",
    "    self.down1 = Downsample(16, 5)\n",
    "    self.down2 = Downsample(32, 5)\n",
    "    self.down3 = Downsample(64, 5)\n",
    "    self.down4 = Downsample(128, 5)\n",
    "    self.down5 = Downsample(256, 5)\n",
    "    self.down6 = Downsample(512, 5)\n",
    "    \n",
    "    self.up1 = Upsample(256, 5, apply_dropout=True)\n",
    "    self.up2 = Upsample(128, 5, apply_dropout=True)\n",
    "    self.up3 = Upsample(64, 5, apply_dropout=True)\n",
    "    self.up4 = Upsample(32, 5)\n",
    "    self.up5 = Upsample(16, 5)\n",
    "    \n",
    "    self.last = tf.keras.layers.Conv2DTranspose(1, #OUTPUT_CHANNELS\n",
    "                                                (5, 5), \n",
    "                                                strides=2, \n",
    "                                                padding='same',\n",
    "                                                kernel_initializer=initializer)\n",
    "  \n",
    "  @tf.contrib.eager.defun\n",
    "  def call(self, x, training):\n",
    "    # x shape == (bs, 512, 128, 1)    \n",
    "    x1 = self.down1(x, training=training) # (bs, 256, 64, 16)\n",
    "    x2 = self.down2(x1, training=training) # (bs, 128, 32, 32)\n",
    "    x3 = self.down3(x2, training=training) # (bs, 64, 16, 64)\n",
    "    x4 = self.down4(x3, training=training) # (bs, 32, 8, 128)\n",
    "    x5 = self.down5(x4, training=training) # (bs, 16, 4, 256)\n",
    "    x6 = self.down6(x5, training=training) # (bs, 8, 2, 512)    \n",
    "\n",
    "    x7 = self.up1(x6, x5, training=training) # (bs, 16, 4, 256)\n",
    "    x8 = self.up2(x7, x4, training=training) # (bs, 32, 8, 128)\n",
    "    x9 = self.up3(x8, x3, training=training) # (bs, 64, 16, 64)\n",
    "    x10 = self.up4(x9, x2, training=training) # (bs, 128, 32, 32)\n",
    "    x11 = self.up5(x10, x1, training=training) # (bs, 256, 64, 16)\n",
    "    \n",
    "    x12 = self.last(x11) # (bs, 512, 128, 1)\n",
    "    x13 = tf.nn.tanh(x12)\n",
    "\n",
    "    return x13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpectrogramChannelsUNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.constant([1, 2]) * tf.constant([2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loss function to be optimized\n",
    "def loss(mask, mixture, target):\n",
    "    mae = tf.keras.losses.MAE((mask * mixture), targets)\n",
    "    return tf.reduce_mean(mae)\n",
    "\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17438972\n",
      "0.13549604\n",
      "0.1627253\n",
      "0.16768746\n",
      "0.15774262\n",
      "0.1581802\n",
      "0.18270281\n",
      "0.15513977\n",
      "0.13489163\n",
      "0.13389716\n",
      "0.14207926\n",
      "0.137745\n",
      "0.14833662\n",
      "0.13203382\n",
      "0.16116506\n",
      "0.14065489\n",
      "0.13761377\n",
      "0.13966236\n",
      "0.16630752\n",
      "0.16217561\n",
      "0.18096146\n",
      "0.17479874\n",
      "0.16842443\n",
      "0.21351776\n",
      "0.15991601\n",
      "0.15410852\n",
      "0.18181835\n",
      "0.18500432\n",
      "0.18466529\n",
      "0.18146083\n",
      "0.17682369\n",
      "0.16609979\n",
      "0.21200842\n",
      "0.1715177\n",
      "0.15307137\n",
      "0.16380733\n",
      "0.17596932\n",
      "0.1776322\n",
      "0.17703666\n",
      "0.1689827\n",
      "0.16732062\n",
      "0.16513914\n",
      "0.14752947\n",
      "0.17941774\n",
      "0.18015602\n",
      "0.18523388\n",
      "0.1548334\n",
      "0.16107185\n",
      "0.17408752\n",
      "0.180076\n",
      "0.13717848\n",
      "0.13075906\n",
      "0.16254312\n",
      "0.17640615\n",
      "0.1603344\n",
      "0.16533434\n",
      "0.14193028\n",
      "0.18052402\n",
      "0.14285341\n",
      "0.15650919\n",
      "0.16770941\n",
      "0.15208648\n",
      "0.22039983\n",
      "0.17831582\n",
      "0.15746094\n",
      "0.17132315\n",
      "0.21732365\n",
      "0.18463273\n",
      "0.15467647\n",
      "0.15902914\n",
      "0.16382195\n",
      "0.21801022\n",
      "0.18448743\n",
      "0.17364337\n",
      "0.19178307\n",
      "0.22444627\n",
      "0.15017024\n",
      "0.18999913\n",
      "0.17095539\n",
      "0.2092202\n",
      "0.17465582\n",
      "0.14467487\n",
      "0.20117772\n",
      "0.20129387\n",
      "0.19109887\n",
      "0.17886178\n",
      "0.20767376\n",
      "0.19907999\n",
      "0.17359787\n",
      "0.1794733\n",
      "0.14190751\n",
      "0.1532608\n",
      "0.22263588\n",
      "0.15750185\n",
      "0.15483408\n",
      "0.18012266\n",
      "0.14388482\n",
      "0.16562971\n",
      "0.17309918\n",
      "0.23744798\n"
     ]
    }
   ],
   "source": [
    "opt = tf.train.AdamOptimizer()\n",
    "\n",
    "for mixtures, targets in train_dataset.take(100): \n",
    "  with tf.GradientTape() as tape:\n",
    "    mask = model(mixtures, training=True)\n",
    "    loss_value = loss(mask, mixtures, targets[...,1:2])\n",
    "  \n",
    "  grads = tape.gradient(loss_value, model.variables)\n",
    "  opt.apply_gradients(zip(grads, model.variables),\n",
    "                      global_step=tf.train.get_or_create_global_step())\n",
    "\n",
    "  loss_history.append(loss_value.numpy())\n",
    "  print(loss_value.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20566222\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
