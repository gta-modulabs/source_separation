{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert wave to spectrogram to tfrecords format\n",
    "\n",
    "* Sampling down: 44100 -> 8192\n",
    "* track 단위로 stft를 수행 (train 기준 총 100개의 파일 단위로 fft)\n",
    "* track 마다 시간이 많이 달라 (20sec ~ 10min for train) track을 일정 구간으로 자름\n",
    "  * 실제로는 track을 자르지 않고 stft 한 결과인 spectrogram을 time 축으로 자름\n",
    "* spectrogram의 input_data shape이 (512, 128) 이 되도록 맞춤\n",
    "* 데이터 하나는 (512, 192) shape의 spectrogram 임\n",
    "  * 이러면 노래 마지막 부분이 잘리는데 잘리는 부분은 바로 전 part에 merge\n",
    "  * 그래서 마지막 부분 time_step: 192 < time_step < 384\n",
    "* Singing Voice Separation with Deep U-Net Convolutional Networks 논문 데이터 만드는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import musdb\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = musdb.DB(root_dir='./datasets/musdb18/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training tracks\n",
    "split_name = 'train'\n",
    "assert split_name in ['train', 'test']\n",
    "\n",
    "tracks = mus.load_mus_tracks(subsets=[split_name])\n",
    "print(type(tracks))\n",
    "print(len(tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for total time (minute, sec) info\n",
    "# for i, track in enumerate(tracks):\n",
    "#   sec = track.audio.T.shape[1]/44100\n",
    "#   minute = int(sec / 60)\n",
    "#   sec = sec - minute * 60\n",
    "#   print(\"{}th: {} min {:.2f} sec\".format(i, minute, sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks[0].targets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "print(tracks[index].name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listen the track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original track - mixture\n",
    "display.Audio(tracks[index].audio.T, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tracks[index].audio.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to listen in each stem source then uncomment them\n",
    "# display.Audio(tracks[index].targets['vocals'].audio.T, rate=44100)\n",
    "# display.Audio(tracks[index].targets['drums'].audio.T, rate=44100)\n",
    "# display.Audio(tracks[index].targets['bass'].audio.T, rate=44100)\n",
    "# display.Audio(tracks[index].targets['other'].audio.T, rate=44100)\n",
    "# display.Audio(tracks[index].targets['accompaniment'].audio.T, rate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot for short time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate to left and right channels\n",
    "second = 10\n",
    "left_wave = tracks[index].audio.T[0][:44100 * second]\n",
    "left_wave /= max(abs(left_wave))\n",
    "right_wave = tracks[index].audio.T[1][:44100 * second]\n",
    "right_wave /= max(abs(right_wave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the each channel\n",
    "plt.figure(figsize=[18, 3])\n",
    "plt.plot(left_wave)\n",
    "\n",
    "plt.figure(figsize=[18, 3])\n",
    "plt.plot(right_wave)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(left_wave.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(left_stft[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short-time Fourier Transform\n",
    "# n_fft: number of samples used to calculate fft\n",
    "# hop_length: like concept of stride\n",
    "left_stft = librosa.core.stft(left_wave, n_fft=2048, hop_length=512)\n",
    "print(left_stft.shape)\n",
    "print(type(left_stft[0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_abs = abs(left_stft)\n",
    "librosa.display.specshow(left_abs)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(left_abs, ref=np.max))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrogram using normalize (for maybe standard method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_level_db = -100\n",
    "ref_level_db = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram(y):\n",
    "  D = _stft(y)\n",
    "  S = _amp_to_db(np.abs(D)) - ref_level_db\n",
    "  return _normalize(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _stft(y):\n",
    "  #n_fft, hop_length, win_length = 2048, 512, 2048\n",
    "  n_fft, hop_length, win_length = 1024, 512, 1024\n",
    "  return librosa.stft(y=y, n_fft=n_fft, hop_length=hop_length, win_length=win_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _amp_to_db(x):\n",
    "  return 20 * np.log10(np.maximum(1e-5, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize(S):\n",
    "  return np.clip((S - min_level_db) / -min_level_db, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_spec = spectrogram(left_wave)\n",
    "print(left_spec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "librosa.display.specshow(left_spec)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to tfrecords format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int64_feature(values):\n",
    "  \"\"\"Returns a TF-Feature of int64s.\n",
    "\n",
    "  Args:\n",
    "    values: A scalar or list of values.\n",
    "\n",
    "  Returns:\n",
    "    A TF-Feature.\n",
    "  \"\"\"\n",
    "  if not isinstance(values, (tuple, list)):\n",
    "    values = [values]\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=values))\n",
    "\n",
    "\n",
    "def bytes_feature(values):\n",
    "  \"\"\"Returns a TF-Feature of bytes.\n",
    "\n",
    "  Args:\n",
    "    values: A string.\n",
    "\n",
    "  Returns:\n",
    "    A TF-Feature.\n",
    "  \"\"\"\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))\n",
    "\n",
    "\n",
    "def float_feature(values):\n",
    "  \"\"\"Returns a TF-Feature of floats.\n",
    "\n",
    "  Args:\n",
    "    values: A scalar of list of values.\n",
    "\n",
    "  Returns:\n",
    "    A TF-Feature.\n",
    "  \"\"\"\n",
    "  if not isinstance(values, (tuple, list)):\n",
    "    values = [values]\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_dataset_filename(dataset_dir, split_name, shard_id, num_shards):\n",
    "  output_filename = 'spectrogram_%s_%05d-of-%05d.tfrecord' % (\n",
    "      split_name, shard_id, num_shards)\n",
    "  return os.path.join(dataset_dir, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dataset(split_name, dataset_dir, N, num_shards):\n",
    "  \"\"\"Converts the spectrogram of given tracks to a TFRecord dataset.\n",
    "\n",
    "  Args:\n",
    "    split_name: The name of the dataset, either 'train' or 'validation'.\n",
    "    dataset_dir: The directory where the converted datasets are stored.\n",
    "    N: number of total examples # train: 100, test: 50\n",
    "    num_shards: number of shards\n",
    "  \"\"\"\n",
    "  assert split_name in ['train', 'test']\n",
    "\n",
    "  # data split\n",
    "  spectrogram_datadir = os.path.join(dataset_dir, split_name)\n",
    "  print(spectrogram_datadir)\n",
    "  \n",
    "  num_per_shard = int(N / float(num_shards))\n",
    "\n",
    "  for shard_id in range(num_shards):\n",
    "    output_filename = _get_dataset_filename(\n",
    "              spectrogram_datadir, split_name, shard_id, num_shards)\n",
    "    print('Writing', output_filename)\n",
    "\n",
    "    # step 1\n",
    "    with tf.python_io.TFRecordWriter(output_filename) as tfrecord_writer:\n",
    "      start_ndx = shard_id * num_per_shard\n",
    "      end_ndx = min((shard_id+1) * num_per_shard, N)\n",
    "\n",
    "      for i in range(start_ndx, end_ndx):\n",
    "        sys.stdout.write('\\r>> Converting spectrogram %d/%d shard %d\\n' % (\n",
    "            i+1, N, shard_id))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        mixtures = tracks[i].audio.T\n",
    "        vocals = tracks[i].targets['vocals'].audio.T\n",
    "        drums = tracks[i].targets['drums'].audio.T\n",
    "        basses = tracks[i].targets['bass'].audio.T\n",
    "        others = tracks[i].targets['other'].audio.T\n",
    "        accompaniments = tracks[i].targets['accompaniment'].audio.T\n",
    "        number_of_samples = len(mixtures[0])        \n",
    "\n",
    "        sources = [mixtures, vocals, drums, basses, others, accompaniments]\n",
    "        for k, wave in enumerate(sources):\n",
    "          left_wave = wave[0]\n",
    "          right_wave = wave[1]\n",
    "          # resampling\n",
    "          left_wave_8192 = librosa.resample(left_wave, orig_sr=44100, target_sr=8192)\n",
    "          right_wave_8192 = librosa.resample(right_wave, orig_sr=44100, target_sr=8192)\n",
    "\n",
    "          left_spec = np.expand_dims(spectrogram(left_wave_8192), axis=2)\n",
    "          right_spec = np.expand_dims(spectrogram(right_wave_8192), axis=2)\n",
    "          \n",
    "          left_spec\n",
    "\n",
    "          if k == 0:\n",
    "            left_spec_concat = left_spec\n",
    "            right_spec_concat = right_spec\n",
    "          else:\n",
    "            left_spec_concat = np.concatenate((left_spec_concat, left_spec), axis=2)\n",
    "            right_spec_concat = np.concatenate((right_spec_concat, right_spec), axis=2)\n",
    "\n",
    "          time_step_for_example = 192\n",
    "          num_split = int(left_spec_concat.shape[1] / time_step_for_example) # time_step: 192 for one data\n",
    "\n",
    "          print(\"{}th data; shape: {}, num_split: {}\".format(i, left_spec_concat.shape, num_split))\n",
    "\n",
    "        channle_info = [b'left', b'right']\n",
    "        for channel_index, spec_concat in enumerate([left_spec_concat, right_spec_concat]):\n",
    "          for split_index in range(num_split-1):\n",
    "            if split_index > 0:\n",
    "              break\n",
    "            # step 2\n",
    "            spec_raw = spec_concat[:512, split_index*time_step_for_example:(split_index+1)*time_step_for_example]\n",
    "            frequency_bin = spec_raw.shape[0]\n",
    "            time_step = spec_raw.shape[1]\n",
    "            spec_raw_string = spec_raw.tostring()\n",
    "            channel = channle_info[channel_index]\n",
    "            print(\"{}th track; {}th split\".format(i, split_index))\n",
    "\n",
    "            # step 3:\n",
    "            features = tf.train.Features(feature={'spec_raw': bytes_feature(spec_raw_string),\n",
    "                                                  'frequency_bin': int64_feature(frequency_bin),\n",
    "                                                  'time_step': int64_feature(time_step),\n",
    "                                                  'channel': bytes_feature(channel),\n",
    "                                                 })\n",
    "\n",
    "            # step 4\n",
    "            example = tf.train.Example(features=features)\n",
    "\n",
    "            # step 5\n",
    "            tfrecord_writer.write(example.SerializeToString())\n",
    "\n",
    "          # merge between last split part and residual part\n",
    "          # step 2\n",
    "          spec_raw = spec_concat[:512, (split_index+1)*time_step_for_example:]\n",
    "          frequency_bin = spec_raw.shape[0]\n",
    "          time_step = spec_raw.shape[1]\n",
    "          spec_raw_string = spec_raw.tostring()\n",
    "          channel = channle_info[channel_index]\n",
    "          print(\"{}th track; {}th split\".format(i, split_index+1))\n",
    "\n",
    "          # step 3:\n",
    "          features = tf.train.Features(feature={'spec_raw': bytes_feature(spec_raw_string),\n",
    "                                                'frequency_bin': int64_feature(frequency_bin),\n",
    "                                                'time_step': int64_feature(time_step),\n",
    "                                                'channel': bytes_feature(channel),\n",
    "                                               })\n",
    "\n",
    "          # step 4\n",
    "          example = tf.train.Example(features=features)\n",
    "\n",
    "          # step 5\n",
    "          tfrecord_writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram_data_dir = './datasets/spectrogram'\n",
    "NUM_SHARDS = 10 # for train: 20, for test: 10\n",
    "N = 10 # for train: 100, for test: 50\n",
    "convert_dataset(split_name, spectrogram_data_dir, N, NUM_SHARDS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
