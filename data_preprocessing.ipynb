{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wave to Spectrogram\n",
    "\n",
    "* 11.9초 단위로 자른 wav file을 stft(Short-time Fourier Transfromation)를 이용하여 (time, frequency) domain으로 바꿈\n",
    "* 바꾼 그림을 각각 그림 파일 (jpg)로 저장\n",
    "* Singing Voice Separation with Deep U-Net Convolutional Networks 논문 데이터 만드는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import imageio\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import musdb\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = musdb.DB(root_dir='./datasets/musdb18/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training tracks\n",
    "tracks = mus.load_mus_tracks(subsets=['train'])\n",
    "print(type(tracks))\n",
    "print(len(tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks[0].targets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "print(tracks[index].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original track - mixture\n",
    "display.Audio(tracks[index].audio.T, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tracks[index].audio.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to listen in each stem source then uncomment them\n",
    "# display.Audio(tracks[index].targets['vocals'].audio.T, rate=44100)\n",
    "# display.Audio(tracks[index].targets['drums'].audio.T, rate=44100)\n",
    "# display.Audio(tracks[index].targets['bass'].audio.T, rate=44100)\n",
    "# display.Audio(tracks[index].targets['other'].audio.T, rate=44100)\n",
    "# display.Audio(tracks[index].targets['accompaniment'].audio.T, rate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot for short time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate to left and right channels\n",
    "second = 10\n",
    "left_wave = tracks[index].audio.T[0][:44100 * second]\n",
    "left_wave /= max(abs(left_wave))\n",
    "right_wave = tracks[index].audio.T[1][:44100 * second]\n",
    "right_wave /= max(abs(right_wave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the each channel\n",
    "plt.figure(figsize=[18, 3])\n",
    "plt.plot(left_wave)\n",
    "\n",
    "plt.figure(figsize=[18, 3])\n",
    "plt.plot(right_wave)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(left_wave.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(left_stft[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short-time Fourier Transform\n",
    "# n_fft: number of samples used to calculate fft\n",
    "# hop_length: like concept of stride\n",
    "left_stft = librosa.core.stft(left_wave, n_fft=2048, hop_length=512)\n",
    "print(left_stft.shape)\n",
    "print(type(left_stft[0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_abs = abs(left_stft)\n",
    "librosa.display.specshow(left_abs)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(left_abs, ref=np.max))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrogram using normalize (for maybe standard form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_level_db = -100\n",
    "ref_level_db = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram(y):\n",
    "  D = _stft(y)\n",
    "  S = _amp_to_db(np.abs(D)) - ref_level_db\n",
    "  return _normalize(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _stft(y):\n",
    "  #n_fft, hop_length, win_length = 2048, 512, 2048\n",
    "  n_fft, hop_length, win_length = 1024, 768, 1024\n",
    "  return librosa.stft(y=y, n_fft=n_fft, hop_length=hop_length, win_length=win_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _amp_to_db(x):\n",
    "  return 20 * np.log10(np.maximum(1e-5, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize(S):\n",
    "  return np.clip((S - min_level_db) / -min_level_db, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_spec = spectrogram(left_wave)\n",
    "print(left_spec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "librosa.display.specshow(left_spec)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split\n",
    "spectrogram_datadir = './datasets/spectrogram_jpg/train'\n",
    "second = 11.90625 # split in about 11.9 seconds\n",
    "for i, track in enumerate(tracks):\n",
    "  number = int(track.audio.T.shape[1] / second / 44100)\n",
    "  interval = int(second * 44100)\n",
    "  for j in range(number):\n",
    "    print(\"# {} track: {}th part\".format(i, j))\n",
    "    mixtures = track.audio.T[:, j*interval:(j+1)*interval]\n",
    "    vocals = track.targets['vocals'].audio.T[:, j*interval:(j+1)*interval]\n",
    "    drums = track.targets['drums'].audio.T[:, j*interval:(j+1)*interval]\n",
    "    basses = track.targets['bass'].audio.T[:, j*interval:(j+1)*interval]\n",
    "    others = track.targets['other'].audio.T[:, j*interval:(j+1)*interval]\n",
    "    accompaniments = track.targets['accompaniment'].audio.T[:, j*interval:(j+1)*interval]\n",
    "    \n",
    "    sources = [mixtures, vocals, drums, basses, others, accompaniments]\n",
    "    for k, wave in enumerate(sources):\n",
    "      left_wave = wave[0]\n",
    "      right_wave = wave[1]\n",
    "      # resampling\n",
    "      left_wave_8192 = librosa.resample(left_wave, orig_sr=44100, target_sr=8192)\n",
    "      right_wave_8192 = librosa.resample(left_wave, orig_sr=44100, target_sr=8192)\n",
    "      \n",
    "      left_spec = spectrogram(left_wave_8192) # (513, 128) shape\n",
    "      right_spec = spectrogram(right_wave_8192) # (513, 128) shape\n",
    "      print(left_spec.shape)\n",
    "      \n",
    "      if k == 0:\n",
    "        left_concat = left_spec\n",
    "        right_concat = right_spec\n",
    "      else:\n",
    "        left_concat = np.concatenate((left_concat, left_spec), axis=1)\n",
    "        right_concat = np.concatenate((right_concat, right_spec), axis=1)\n",
    "        \n",
    "    display.clear_output(wait=True)\n",
    "    filename_l = 'track{}.part{}.left.jpg'.format(i, j)\n",
    "    filename_r = 'track{}.part{}.right.jpg'.format(i, j)\n",
    "    print(filename_l, filename_r)\n",
    "    \n",
    "    imageio.imwrite(os.path.join(spectrogram_datadir, filename_l), left_concat[:512,])\n",
    "    imageio.imwrite(os.path.join(spectrogram_datadir, filename_r), right_concat[:512,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
