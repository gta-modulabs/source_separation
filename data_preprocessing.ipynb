{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wave to Spectrogram\n",
    "\n",
    "* 11.999초 단위로 자른 wav file을 stft(Short-time Fourier Transfromation)를 이용하여 (time, frequency) domain으로 바꿈\n",
    "* 바꾼 그림을 각각 그림 파일 (jpg)로 저장\n",
    "* Singing Voice Separation with Deep U-Net Convolutional Networks 논문 데이터 만드는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import musdb\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = musdb.DB(root_dir='./datasets/musdb18/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training tracks\n",
    "tracks = mus.load_mus_tracks(subsets=['train'])\n",
    "print(type(tracks))\n",
    "print(len(tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks[0].targets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "print(tracks[index].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original track - mixture\n",
    "display.Audio(tracks[index].audio.T, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tracks[index].audio.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to listen in each stem source then uncomment them\n",
    "# display.Audio(tracks[index].targets['vocals'].audio.T, rate=44100)\n",
    "# display.Audio(tracks[index].targets['drums'].audio.T, rate=44100)\n",
    "# display.Audio(tracks[index].targets['bass'].audio.T, rate=44100)\n",
    "# display.Audio(tracks[index].targets['other'].audio.T, rate=44100)\n",
    "# display.Audio(tracks[index].targets['accompaniment'].audio.T, rate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot for short time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate to left and right channels\n",
    "second = 10\n",
    "left_wave = tracks[index].audio.T[0][:44100 * second]\n",
    "left_wave /= max(abs(left_wave))\n",
    "right_wave = tracks[index].audio.T[1][:44100 * second]\n",
    "right_wave /= max(abs(right_wave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the each channel\n",
    "plt.figure(figsize=[18, 3])\n",
    "plt.plot(left_wave)\n",
    "\n",
    "plt.figure(figsize=[18, 3])\n",
    "plt.plot(right_wave)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(left_wave.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(left_stft[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short-time Fourier Transform\n",
    "# n_fft: number of samples used to calculate fft\n",
    "# hop_length: like concept of stride\n",
    "left_stft = librosa.core.stft(left_wave, n_fft=2048, hop_length=512)\n",
    "print(left_stft.shape)\n",
    "print(type(left_stft[0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_abs = abs(left_stft)\n",
    "librosa.display.specshow(left_abs)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(left_abs, ref=np.max))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrogram using normalize (for maybe standard form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_level_db = -100\n",
    "ref_level_db = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram(y):\n",
    "  D = _stft(y)\n",
    "  S = _amp_to_db(np.abs(D)) - ref_level_db\n",
    "  return _normalize(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _stft(y):\n",
    "  #n_fft, hop_length, win_length = 2048, 512, 2048\n",
    "  n_fft, hop_length, win_length = 1024, 512, 1024\n",
    "  return librosa.stft(y=y, n_fft=n_fft, hop_length=hop_length, win_length=win_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _amp_to_db(x):\n",
    "  return 20 * np.log10(np.maximum(1e-5, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize(S):\n",
    "  return np.clip((S - min_level_db) / -min_level_db, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_spec = spectrogram(left_wave)\n",
    "print(left_spec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "librosa.display.specshow(left_spec)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int64_feature(values):\n",
    "  \"\"\"Returns a TF-Feature of int64s.\n",
    "\n",
    "  Args:\n",
    "    values: A scalar or list of values.\n",
    "\n",
    "  Returns:\n",
    "    A TF-Feature.\n",
    "  \"\"\"\n",
    "  if not isinstance(values, (tuple, list)):\n",
    "    values = [values]\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=values))\n",
    "\n",
    "\n",
    "def bytes_feature(values):\n",
    "  \"\"\"Returns a TF-Feature of bytes.\n",
    "\n",
    "  Args:\n",
    "    values: A string.\n",
    "\n",
    "  Returns:\n",
    "    A TF-Feature.\n",
    "  \"\"\"\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))\n",
    "\n",
    "\n",
    "def float_feature(values):\n",
    "  \"\"\"Returns a TF-Feature of floats.\n",
    "\n",
    "  Args:\n",
    "    values: A scalar of list of values.\n",
    "\n",
    "  Returns:\n",
    "    A TF-Feature.\n",
    "  \"\"\"\n",
    "  if not isinstance(values, (tuple, list)):\n",
    "    values = [values]\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_NUM_SHARDS = 10\n",
    "def _get_dataset_filename(dataset_dir, split_name, shard_id):\n",
    "  output_filename = 'spectrogram_%s_%05d-of-%05d.tfrecord' % (\n",
    "      split_name, shard_id, _NUM_SHARDS)\n",
    "  return os.path.join(dataset_dir, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split\n",
    "spectrogram_datadir = './datasets/spectrogram/train'\n",
    "\n",
    "N = 100 # number of total examples\n",
    "num_per_shard = int(N / float(_NUM_SHARDS))\n",
    "split_name = 'train'\n",
    "\n",
    "for shard_id in range(_NUM_SHARDS):\n",
    "  output_filename = _get_dataset_filename(\n",
    "            spectrogram_datadir, split_name, shard_id)\n",
    "  print('Writing', output_filename)\n",
    "  \n",
    "  with tf.python_io.TFRecordWriter(output_filename) as writer:\n",
    "    start_ndx = shard_id * num_per_shard\n",
    "    end_ndx = min((shard_id+1) * num_per_shard, N)\n",
    "    \n",
    "    for i in range(start_ndx, end_ndx):\n",
    "      sys.stdout.write('\\r>> Converting spectrogram %d/%d shard %d\\n' % (\n",
    "          i+1, N, shard_id))\n",
    "      sys.stdout.flush()\n",
    "      \n",
    "      mixtures = tracks[i].audio.T\n",
    "      vocals = tracks[i].targets['vocals'].audio.T\n",
    "      drums = tracks[i].targets['drums'].audio.T\n",
    "      basses = tracks[i].targets['bass'].audio.T\n",
    "      others = tracks[i].targets['other'].audio.T\n",
    "      accompaniments = tracks[i].targets['accompaniment'].audio.T\n",
    "      number_of_samples = len(mixtures[0])\n",
    "      print(\"number_of_samples\", number_of_samples)\n",
    "\n",
    "      sources = [mixtures, vocals, drums, basses, others, accompaniments]\n",
    "      for k, wave in enumerate(sources):\n",
    "        left_wave = wave[0]\n",
    "        right_wave = wave[1]\n",
    "        # resampling\n",
    "        left_wave_8192 = librosa.resample(left_wave, orig_sr=44100, target_sr=8192)\n",
    "        right_wave_8192 = librosa.resample(left_wave, orig_sr=44100, target_sr=8192)\n",
    "\n",
    "        left_spec = spectrogram(left_wave_8192)\n",
    "        right_spec = spectrogram(right_wave_8192)\n",
    "\n",
    "        if k == 0:\n",
    "          left_concat = left_spec\n",
    "          right_concat = right_spec\n",
    "        else:\n",
    "          left_concat = np.concatenate((left_concat, left_spec), axis=1)\n",
    "          right_concat = np.concatenate((right_concat, right_spec), axis=1)\n",
    "\n",
    "        left_spec_raw = left_concat[:512,].tostring()\n",
    "        right_spec_raw = right_concat[:512,].tostring()\n",
    "\n",
    "        for spec_raw in [left_spec_raw, right_spec_raw]:\n",
    "          example = tf.train.Example(\n",
    "            features=tf.train.Features(\n",
    "                feature={\n",
    "                    'spec_raw': bytes_feature(spec_raw),\n",
    "                    'number_of_samples': int64_feature(number_of_samples),\n",
    "                }))\n",
    "          writer.write(example.SerializeToString())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
